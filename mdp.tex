\subsection{Markov Decision Processes}


\begin{wrapfigure}{r}{.5\columnwidth}
  \centering
    \resizebox{.4\columnwidth}{!}{
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
      distance=2cm,node/.style={circle,draw}]
      \node[node] (p) at ( 0,  1.5) { $+$ };
      \node[node] (q) at ( 0, -1.5) { $-$ };
      \node[node] (F) at (-1.5,  0) { $Y$ };
      \node[node] (T) at ( 1.5,  0) { $N$ };

      \path
      (p) edge [bend right=45] node [left] { $L, .75$ } (F)
      (p) edge [bend left=45] node [right] { $L, .25$ } (T)
      (p) edge [bend left=45] node [right=-12,above] { $H, .8$ } (F)
      (p) edge [bend right=45] node [right=12,above] { $H, .2$ } (T)

      (q) edge [bend left=45] node [left] { $L, .25$ } (F)
      (q) edge [bend right=45] node [right] { $L, .75$ } (T)
      (q) edge [bend right=45] node [left=12,below] { $H, .2$ } (F)
      (q) edge [bend left=45] node [right=12,below] { $H, .8$ } (T)

      (F) edge [loop left] node [below] { $-, 1$ } (F)
      (T) edge [loop right] node [below] { $-, 1$ } (T)
      ;
      \end{tikzpicture}
    }
    \caption{Markov Decision Process}
    \label{figure:simple-mdp}
\end{wrapfigure}

\hide{Mechanisms are not necessarily closed randomized algorithms; they may
perform different compution on users' requests.
We use Markov decision processes to model such
interactive mechanisms. Specifically, external inputs are modeled by
actions. Behaviors associated with different inputs are modeled by
distributions associated with actions.
}

As we describe earlier, the user has the possibility of querying multiple mechanisms.
We use Markov decision processes to model such
interactive mechanisms. Specifically, external inputs are modeled by
actions. Behaviors associated with different inputs are modeled by
distributions associated with actions.


Consider again the survey mechanism. Suppose we would like to design
an interactive mechanism which adjusts random noises on surveyers'
requests. When the surveyer requests low-accuracy answers, the
surveyee uses the survey mechanism as before. When high-accuracy
answers are requested, the surveyee answers \textit{Yes} with
probability $4/5$ and \textit{No} with probability $1/5$ when she has
positive diagnosis. She answers \textit{Yes} with probability $1/5$
and \textit{No} with probability $4/5$ when she is not
diagnosed with the disease X. This gives an interactive mechanism
corresponding to the MDP shown in
Figure~\ref{figure:simple-mdp}.\lz{remove the loops}

In the figure, the states $+$,
$-$, $Y$, and $N$ are interpreted as before. The actions $L$ and $H$
denote low- and high-accuracy requests respectively. Let $M_H$ denote
the Markov chain derived by high-accuracy requests.
Observe that $1/5 \leq \Pr[M_H(x) = Y] \leq 4/5$ for any $x
\in \mathcal{X}$. Hence $\Pr[M_H (x) = Y] \leq 4/5 = 4 \cdot 1/5 \leq
4 \Pr[M_H (x') = Y]$ for any neighboring $x, x' \in
\mathcal{X}$. Similarly, $\Pr[M_H (x) = N] \leq 4 \Pr[M_H (x') =
N]$. The high-accuracy mechanism is $(\ln 4,0)$-differentially private.
The privacy guarantees vary from accuracy requests.

\subsection{Semantics}
The logic $\dpCTLstar$ can be interpreted over MDPs. Semantics over Markov chains generalizes to MDPs as well. Note that two states with different enabled actions
are trivially distinguishable; no privacy can be preserved.
Let $M = (S, \Act, \wp, L)$ be an MDP. Define the satisfaction
relation $M, \neighbor{S}, s \models \Phi$ for $\PJ{J}$ and $\dpriv{\epsilon}{\delta} \phi$ (others are standard) as follows.
\begin{eqnarray*}
%  M, \neighbor{S}, s \models \top\\
%  M, \neighbor{S}, s \models p  & \textmd{ if } &  p \in L(s)\\
%  M, \neighbor{S}, s \models \neg \Phi  & \textmd{ if } &  M, \neighbor{S}, s \not\models \Phi\\
%  M, \neighbor{S}, s \models \Phi_0 \wedge \Phi_1  & \textmd{ if } &  M, \neighbor{S}, s \models \Phi_0 \textmd{ and }
%  M, \neighbor{S}, s \models \Phi_1\\
  M, \neighbor{S}, s \models \PJ{J} \phi
  & \textmd{ if } &
  \myPr{s}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} \in J
  \textmd{ for every scheduler } \scheduler{S}\\
  M, \neighbor{S}, s \models \dpriv{\epsilon}{\delta} \phi
  & \textmd{ if } &
  \textmd{for all } t \textmd{ with } s \neighbor{S} t \textmd{ and
   scheduler } \scheduler{S},
   \myPr{s}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} \leq
  e^{\epsilon} \cdot
   \\
  & &
   \myPr{t}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} + \delta
   \textmd{ and }
   \myPr{t}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} \leq e^{\epsilon} \cdot
   \myPr{s}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} + \delta
\end{eqnarray*}

Recall that $M_{\scheduler{S}}$ is but a Markov chain. The semantics
of $M_{\scheduler{S}}, \neighbor{S}, \pi \models \phi$ and hence the
probability $\myPr{s}{M_{\scheduler{S}}}{\neighbor{S}}{\phi}$ are
defined as in Markov chains.
The semantics of $\dpCTLstar$ on MDPs
is again standard except the differentially private operator
$\dpriv{\epsilon}{\delta}$. For any path formula $\phi$,
$\dpriv{\epsilon}{\delta} \phi$ specifies states which are $(\epsilon,
\delta)$-close to all its neighbors in having paths satisfying $\phi$
for arbitrary schedulers. That is, no
position-independent scheduler can force any of neighbors to have
probabilistically distinguishable behaviors.

\noindent
\emph{Justification of the scheduler class.}
For MDPs a richer class of scheduler classes have been considered in the literature, see \cite{BK:08:PMC}. It may depend on the full history of state and action sequences, and the decision can be randomised. If we use such scheduler, another definition of the differentially private operator
might be:\lz{put $bad$ on $\models$?}
\begin{eqnarray*}
  M, \neighbor{S}, s \models \dpriv{\epsilon}{\delta}^{\mathit{bad}} \phi
  & \textmd{ if } &
  \textmd{for all } t \textmd{ with } s \neighbor{S} t \textmd{ and
  scheduler } \scheduler{S},
  \myPr{s}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} \leq
  e^{\epsilon} \cdot\\
  && \myPr{t}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} + \delta \textmd{ and }
  \myPr{t}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} \leq
  e^{\epsilon} \cdot \myPr{s}{M_{\scheduler{S}}}{\neighbor{S}}{\phi}
  + \delta
\end{eqnarray*}
A state satisfies $\dpriv{\epsilon}{\delta}^{\mathit{bad}} \phi$ if
no scheduler could differentiate the probabilities of paths satisfying
$\phi$ from neighbors. Such a definition would allow strategies to
take different actions from different states. It might need different
action sequences to distinguish \lz{or mimic?} neighbors. \lz{add However,?}Two neighbors could still be
differentiated by an action sequence and lose their privacy.

We consider only sequences $\scheduler{S}\in Act^\omega$, which correspond to the query sequences. In the differential privacy context, neighbor states exhibit same action behaviours. And we will see later that
our semantics agrees with the notion of differential privacy in the literature for such systems.
Wpe hence
prefer the original definition.

\subsection{Model Checking Algorithm}
For an MDP $M =
(S, \Act, \wp, L)$, we want to compute $\{ M, \neighbor{S}, s \models
\dpriv{\epsilon}{\delta} \phi \}$ . Recall the semantics of $\dpriv{\epsilon}{\delta}
\phi$. Given $s, t$ with $s \neighbor{M} t$ and a path formula
$\phi$, we need to decide whether
$\myPr{s}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} \leq
e^{\epsilon} \myPr{t}{M_{\scheduler{S}}}{\neighbor{S}}{\phi} + \delta$
for every scheduler $\scheduler{S}$.
If the path formula only contain next operators, it is easy to deal with. For $\phi:=\X B$ with $B\subseteq S$ only one step behaviour needs to be considered, thus only the first action in the query sequence is needed. It can also be easily generalized to nested next operators:  one needs only to enumerate
all actions query sequences of length obtained by the number of nexted $\X$ operators.
In general, the problem is undecidable.

\begin{theorem}
The $\dpCTLstar$ model checking problem for MDPs  is undecidable.
\end{theorem}
\begin{proof}
The proof follows by a reduction from the \emph{emptiness} problem for probabilistic automata.
A \emph{probabilistic automaton}~\cite{Rabin63} is a tuple $\mathcal{A}= (S,\Sigma,M,s_0,F)$ where
\begin{itemize}
  \item $S$ is a finite set of states,
  \item $\Sigma$ is the finite set of input alphabet,
  \item $M: S\times\Sigma\times S \to [0,1]$ such that $\sum_{t\in S} M(s,\alpha,t)=1$ for all $s\in S$ and $\alpha\in \Sigma$,
  \item $s_0\in S$ is the initial state,
  \item $F\subseteq S$ is a set of accepting states.
\end{itemize}

Each input alphabet $\alpha$ induces a stochastic matrix $M(\alpha)$ in the obvious way. Let $\lambda$ denote the empty string. For $\eta\in\Sigma^*$ we define $M(\eta)$ inductively by: $M(\lambda)$ is the identity matrix, $M(x\eta')=M(x)M(\eta')$. Thus, $M(\eta)(s,s')$ denotes the probability of going from $s$ to $s'$ after reading $\eta$. Let $v_F$ denote the characteristic row vector for the set $F$, and $v_{s_0}$ denote the characteristic row vector for the set $\{s_0\}$. Then, the accepting probably of $\eta$ by $\mathcal{A}$ is defined as $v_{s_0}\cdot M(\eta)\cdot (v_F)^c$ where $(v_F)^c$ denotes the transpose of $v_F$. The following \emph{emptiness problem} is know to be undecidable~\cite{Paz71}
%~\cite{Worrell08}:

\paragraph{Emptiness problem:} Given a probabilistic automaton $\mathcal{A}= (S,\Sigma,M,s_0,F)$, whether there exists $\eta\in\Sigma^*$ such that $v_{s_0}\cdot M(\eta)\cdot (v_F)^c > 0$?

Now we establish the proof by reducing the threshold problem to our $\dpCTLstar$ model checking problem. Given the probabilistic automaton  $\mathcal{A}= (S,\Sigma,M,s_0,F)$, assume we have a \emph{primed} copy $\mathcal{A}¡¯= (S¡¯,\Sigma,M',s_0¡¯,\emptyset)$.

Now we construct our MDP  $M =
(S\cupdot S', \Sigma, \wp, L)$ where $\wp(s,a,t)$ equals to $M(s,a,t)$ if $s,t\in S$ and to $M'(s,a,t)$ if $s,t\in S'$. We define the neighbor relation $N_S:=\{(s_0,s_0')\}$ by relating states $s_0,s_0'$. The labelling function $L$ is defined by $L(s)=at_F$ if $s\in F$ and $L(s)=\empty$ otherwise.

\lz{shall we use $\diamond$ for finally?}
Now we consider the formula  $\Phi = \dpriv{1}{0} (\diamond at_F)$. For the reduction we prove $s_0\models \dpriv{1}{0} (\diamond at_F)$ iff for all $\eta\in\Sigma^*$ it holds $v_{s_0}\cdot M(\eta)\cdot (v_F)^c \leq 0$.

\lz{remember explain meaning of $\Sigma^\omega$}
First we assume $s_0\models \dpriv{1}{0} (\diamond at_F)$. By $\dpCTLstar$ semantics we have that for all $\scheduler{S}\in\Sigma^\omega$,
$\myPr{s_0}{M_{\scheduler{S}}}{\neighbor{S}}{\diamond at_F} \leq
  e \cdot
  \myPr{s_0'}{M_{\scheduler{S}}}{\neighbor{S}}{\diamond at_F}$. Observe $\myPr{s_0'}{M_{\scheduler{S}}}{\neighbor{S}}{\diamond at_F}=0$ by construction, thus we have
$\myPr{s_0}{M_{\scheduler{S}}}{\neighbor{S}}{\diamond at_F} \leq
 0$. This implies  $v_{s_0}\cdot M(\eta)\cdot (v_F)^c \leq 0$ for all $\eta\in\Sigma^*$.
 
 For the other direction, assume that all $\eta\in\Sigma^*$ it holds $v_{s_0}\cdot M(\eta)\cdot (v_F)^c \leq 0$. For the sake of contradiction, assume that $s_0\not\models \dpriv{1}{0} (\diamond at_F)$. Since the relation $N_S$ contains only one pair, it implies that there exists a scheduler $\scheduler{S}\in\Sigma^\omega$ such that $\myPr{s_0}{M_{\scheduler{S}}}{\neighbor{S}}{\diamond at_F} >0$. It is then easy to construct a finite sequence $\eta\in\Sigma^*$ with  $v_{s_0}\cdot M(\eta)\cdot (v_F)^c > 0$, a contradiction.
\end{proof}

We consider some decidable special cases. Consider the formula $\phi:=F B$ with $B\subseteq S$ and assume that states in $B$ are absorbing (with only self-loops). For the case $\epsilon=0$, the condition reduces to
$\myPr{s}{M_{\scheduler{S}}}{\neighbor{S}}{F B} -
\myPr{t}{M_{\scheduler{S}}}{\neighbor{S}}{F B}\le \delta$. If $\delta=0$ it is the classical language equivalence problem for probabilistic automata~\cite{Rabin63}, which can be solved in polynomial time \cite{Tzeng92}. However, if $\delta>0$, the problem
becomes an approximate version of the language equivalence problem~\cite{Tzeng92}. To the best of our knowledge, the decision problem is still open, and has only be investigated for the special case when all states are connected~\cite{Tzeng92}. 

\hide{
Since the scheduler attaining the maximally probable
behavior from a state may be different from the scheduler attaining
the maximally probable behavior from its neighbors, two
neighbors may still be distinguished by a scheduler. The
weaker definition does not preserve differential privacy. We hence
prefer the original definition.
}
