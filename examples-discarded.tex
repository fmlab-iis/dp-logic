
\hide{
\begin{definition}
  Let the true query result be $r$. The \emph{$\alpha$-geometric
    mechanism} outputs $r + Z$ where $Z$ is a random variable with the
  distribution $\Pr (Z = z) = \frac{1 - \alpha}{1 + \alpha}\alpha^{|z|}$.
\end{definition}
}

\hide{
\begin{figure}
  \centering
    \begin{subfigure}[c]{.51\columnwidth}
  \resizebox{\columnwidth}{!}{
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
      distance=2cm,node/.style={circle,draw}]
      \node[node] (s0) at ( 0,  0) { $s_0$ };
      \node[node] (s1) at (-2,  0) { $s_1$ };
      \node[node] (s2) at ( 2,  0) { $s_2$ };
      \draw (2, 0) circle [radius=0.25];
      \node[node] (s3) at ( 0, -2) { $s_3$ };

      \path
      (s0) edge [bend right=45] node [below] { $\beta, 1/2$ } (s1)
      (s0) edge [bend left=45] node [below] { $\beta, 1/2$ } (s2)
      (s0) edge [bend right=45] node [above] { $\alpha, 3/4$ } (s2)
      (s0) edge node [right] { $\alpha, 1/4$ } (s3)
      
      (s1) edge [bend right=45] node [above] { $\alpha, 1/2$ } (s0)
      (s1) edge [bend right=45] node [right] { $\alpha, 1/2$ } (s3)

      (s2) edge [loop below] node [below] { $\alpha, 1$ } (s2)

      (s3) edge [loop right] node [right] { $\alpha, 1$ } (s3)
      ;
      \end{tikzpicture}
    }
    \caption{Markov Decision Process}
  \end{subfigure}
  \hspace{0.05\columnwidth}
  \begin{subfigure}[c]{.4\columnwidth}
  \resizebox{\columnwidth}{!}{
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
      distance=2cm,node/.style={circle,draw},box/.style={rectangle,draw}]
      \node[node] (s0) at (   0,    0) { $s_0$ };
      \node[box] (s0a) at ( 1.5, -1.5) { $s_{0,\alpha}$ };
      \node[box] (s0b) at (   0,  1.5) { $s_{0,\beta}$ };
      \node[node] (s1) at (-1.5,  1.5) { $s_1$ };
      \node[box] (s1a) at (-1.5,    0) { $s_{1,\alpha}$ };
      \node[node] (s2) at ( 1.5,    0) { $s_2$ };
      \draw (1.5, 0) circle [radius=0.25];
      \node[box] (s2a) at ( 1.5,  1.5) { $s_{2,\alpha}$ };
      \node[node] (s3) at (   0, -1.5) { $s_3$ };
      \node[box] (s3a) at (-1.5, -1.5) { $s_{3,\alpha}$ };

      \path
      (s0) edge [dashed] node { } (s0a)
      (s0) edge [dashed] node { } (s0b)
      (s0a) edge node [left] { $3/4$ } (s2)
      (s0a) edge node [above] { $1/4$ } (s3)
      (s0b) edge node [below] { $1/2$ } (s1) 
      (s0b) edge node [left] { $1/2$ } (s2) 

      (s1) edge [dashed] node {} (s1a)
      (s1a) edge node [above] { $1/2$ } (s0)
      (s1a) edge node [right] { $1/2$ } (s3)

      (s2) edge [dashed, bend right] node { } (s2a)
      (s2a) edge [bend right] node [left] { $1$ } (s2)

      (s3) edge [dashed, bend right] node { } (s3a)
      (s3a) edge [bend right] node [above] { $1$ } (s3)
      ;
      \end{tikzpicture}
    }
    \caption{Induced Markov Chain}
  \end{subfigure}
  \caption{An MDP and its Induced Markov Chain}
  \label{figure:mdp-mc}
\end{figure}
}

\hide{

Consider
\[
\begin{array}{rcl}
  A & = &
  \left[
     \begin{array}{cccccccccc}
        1 &      &  1 &     &    & -.5 &    &    &    &    \\
       -1 &    1 &    &     &    &     &    &    &    &    \\
          &      & -1 &   1 &    &     &    &    &    &    \\
          &      &    & -.5 &  1 &     &    &    &    &    \\
          &      &    &     & -1 &   1 &    &    &    &    \\
          & -.75 &    & -.5 &    &     &  1 & -1 &    &    \\
          &      &    &     &    &     &    &  1 &    &    \\
          & -.25 &    &     &    & -.5 &    &    &  1 & -1 \\
          &      &    &     &    &     &    &    & -1 &  1 
          \end{array}
  \right]\\
  \vec{x} & = &
     \left[
     \begin{array}{cccccccccc}
       s_{00} & s_{0,\alpha} & s_{01} & s_{0, \beta} &
       s_1 & s_{1, \alpha} &
       s_2 & s_{2, \alpha} &
       s_3 & s_{3, \alpha}
     \end{array}
     \right]^t\\
  \vec{y} & = &
     \left[
     \begin{array}{ccccccccc}
       s_{0} & s_{0,\alpha} & s_{0, \beta} &
       s_1 & s_{1, \alpha} &
       s_2 & s_{2, \alpha} &
       s_3 & s_{3, \alpha}
     \end{array}
     \right]^t\\
  \vec{b} & = &
     \left[
     \begin{array}{ccccccccc}
        1 &  1 &  1 &  1 &  1 &  1 &  1 &  1 &  1 \\
     \end{array}
     \right]^t\\
  \vec{c} & = &
     \left[
     \begin{array}{cccccccccc}
        0 &  0 &  0 &  0 &  0 &  0 &  1 &  0 &  0 &  0 \\
     \end{array}
     \right]^t\\
\end{array}
\]
More succinctly,
\[
     \begin{array}{rrrrrrrrrr|r|r}
       s_{00} & s_{0,\alpha} & s_{01} & s_{0, \beta} &
       s_1 & s_{1, \alpha} &
       s_2 & s_{2, \alpha} &
       s_3 & s_{3, \alpha} & \\
       \hline
        1 &      &  1 &     &    & -.5 &    &    &    &    & s_0 & 1 \\
       -1 &    1 &    &     &    &     &    &    &    &    & s_{0,\alpha} & 1 \\
          &      & -1 &   1 &    &     &    &    &    &    & s_{0,\beta} & 1 \\
          &      &    & -.5 &  1 &     &    &    &    &    & s_1 & 1 \\
          &      &    &     & -1 &   1 &    &    &    &    & s_{1,\alpha} & 1 \\
          & -.75 &    & -.5 &    &     &  1 & -1 &    &    & s_2 & 1 \\
          &      &    &     &    &     &    &  1 &    &    & s_{2,\alpha} & 1 \\
          & -.25 &    &     &    & -.5 &    &    &  1 & -1 & s_3 & 1 \\
          &      &    &     &    &     &    &    & -1 &  1 & s_{3,\alpha} & 1 \\
       \hline
          &      &    &     &    &     &  1 &    &    &    &
          \end{array}
\]

By duallity, we have
\begin{equation*}
  \max \{ \vec{c}^t \vec{x} : A \vec{x} \leq \vec{b}, \vec{x} \geq 0 \}
  =
  \min \{ \vec{b}^t \vec{y} : A^t \vec{y} \geq \vec{c}, \vec{y} \geq 0 \}.
\end{equation*}
The minimization problem gives the linear programming problem
in~\cite{CY:98:MDPRE}. The maximization problem gives the linear
programming problem in~\cite{EKVY:07:MMCMDP}.
}

