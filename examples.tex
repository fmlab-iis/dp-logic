To model differentially private mechanisms by Markov chains, we
formalize inputs (such as databases or query results) as states. 
Randomized computation is modeled by probabilistic transitions. Atomic
propositions are used to designate intended interpretation on states
(such as inputs or outputs). We demonstrates the ideas in examples.

\hide{
For
each input, its output distribution is modeled as a probabilistic
transition. Finally, neighbors are specified by a neighborhood
relation. States are typically labelled with atomic propositions to
signify their intended interpretation (such as inputs or outputs). We
demonstrate the key ideas in examples.

A simple way to design differentially private mechanisms is to add
random noises.
Now we describe our main ideas for  modelling differentially private mechanisms.
A state $s$ stores at least a database $x\in \mathcal{X}^n$, which is the data held by a trusted \emph{curator}. A transition corresponds to a data analysis mechanism.
States are typically labelled with the corresponding outputs
the curator generates. We explain the main idea with some examples.
}

\subsection{Survey Mechanism}
\label{subsec:survey}

Consider the survey question: have you been diagnosed
with the disease $X$? In order to protect surveyees' privacy, each
answers the question as follows. The surveyee first flips a
coin. If it is tail, she answers the question truthfully. Otherwise,
she randomly answers \textit{Yes} or \textit{No}
uniformly (Figure~\ref{figure:2-dp-table})~\cite{DR:14:AFDP}.

Let us analyze the mechanism briefly. The data universe $\mathcal{X}$
is $\{ +, - \}$. The mechanism $M$ is a randomized algorithm with
inputs in $\mathcal{X}$ and outputs in $\{ Y, N \}$. For any $x \in
\mathcal{X}$, we have $\frac{1}{4} \leq \Pr[M (x) = Y] \leq
\frac{3}{4}$. Hence $\Pr[M (x) = Y] \leq \frac{3}{4} = 3 \cdot
\frac{1}{4} \leq e^{\ln 3} \Pr[M (x') = Y]$ for any neighbors $x, x'
\in \mathcal{X}$. Similarly, $\Pr[M (x) = N] \leq e^{\ln 3} \Pr[M (x')
= N]$. The survey mechanism is $(\ln 3, 0)$-differentially private.
The random noise boosts the probability of answering
\textit{Yes} or \textit{No} to at least $\frac{1}{4}$ regardless of
diagnoses. Inferences on individual diagnosis can be plausibly denied.

\begin{figure}
  \centering
  \begin{subfigure}{.48\columnwidth}
      \[
      \begin{array}{|c|c|c|}
        \hline
        &
        \multicolumn{2}{c|}{output}
        \\
        \hline
        state & Y & N \\
        \hline
        + & \frac{3}{4} = \frac{1}{2} \cdot \frac{1}{2} + \frac{1}{2} \cdot 1
          & \frac{1}{4} = \frac{1}{2} \cdot \frac{1}{2} + \frac{1}{2} \cdot 0
        \\
        \hline
        - & \frac{1}{4} = \frac{1}{2} \cdot \frac{1}{2} + \frac{1}{2} \cdot 0
          & \frac{3}{4} = \frac{1}{2} \cdot \frac{1}{2} + \frac{1}{2} \cdot 1
        \\
        \hline
      \end{array}
      \]
    \caption{Survey Mechanism}
    \label{figure:2-dp-table}
  \end{subfigure}
  \hspace{.05\columnwidth}
  \begin{subfigure}{.40\columnwidth}
    \resizebox{\columnwidth}{!}{
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
      distance=2cm,node/.style={circle,draw}]
      \node[node] (p) at ( 0,  .5) { $+$ };
      \node[node] (n) at ( 0, -.5) { $-$ };
      \node[node] (Y) at (-1.5,  0) { $s$ };
      \node at (-1.5, .5) { $\mathit{out}_Y$ };
      \node[node] (N) at ( 1.5,  0) { $t$ };
      \node at ( 1.5, .5) { $\mathit{out}_N$ };

      \path
      (p) edge node [above] { $\frac{3}{4}$ } (Y)
      (p) edge node [above] { $\frac{1}{4}$ } (N)
      (n) edge node [below] { $\frac{1}{4}$ } (Y)
      (n) edge node [below] { $\frac{3}{4}$ } (N)
      ;
      \end{tikzpicture}
    }
    \caption{Corresponding Markov Chain}
    \label{figure:2-dp-mdp}
  \end{subfigure}
  \caption{Survey Mechanism with $\ln 3$-Differential Privacy}
  \label{figure:2-dp}
\end{figure}

Figure~\ref{figure:2-dp-mdp} shows the corresponding Markov chain.
In the figure, the states
$+$ and $-$ denote positive or negative diagnoses 
respectively; the states $s$ and $t$ denote answers to the survey
question and hence $\mathit{out}_Y \in L (s)$ and $\mathit{out}_N
\in L (t)$.
States $+$ and $-$ are neighbors.
Missing transitions (such as those from $s$ and $t$) lead
to a special state $\dagger$ with a self-loop. We omit such transitions
and the state $\dagger$ for clarity.


\subsection{Truncated $\alpha$-Geometric Mechanism}\label{subsec:geometric}
More sophisticated differentially private mechanisms are
available. Consider a query
$f : \mathcal{X}^n \rightarrow \{ 0, 1, \ldots, m \}$. Let $\alpha \in (0, 1)$.
The \emph{$\alpha$-geometric mechanism}
outputs $f(x) + Y$ where $Y$ is a random variable with the geometric
distribution~\cite{GRS:09:UUPM,GRS:12:UUPM} :
\[
\Pr[Y = y] = \frac{1 - \alpha}{1 + \alpha}\alpha^{|y|}
\textmd{ for } y \in \bbfZ.
\]
The $\alpha$-geometric mechanism is oblivious since it has the same
output distribution on any inputs $x, x'$ with $f (x) = f
(x')$. It is $(- {\Delta (f)} \ln \alpha, 0)$-differentially
private for any query $f$ with sensitivity $\Delta (f)$. The range of
the mechanism
however is $\bbfZ$. It may give nonsensical outputs such as
negative integers for non-negative queries.

The \emph{truncated $\alpha$-geometric mechanism over $\{ 0, 1,
  \ldots, m \}$}
outputs $f (x) + Z$ where $Z$ is a random variable with the following
distribution:
\[
\Pr[Z = z] =
\left\{
  \begin{array}{ll}
    0 & \textmd{ if } z < - f (x) \\
    \frac{\alpha^{f (x)}}{1 + \alpha} & \textmd{ if } z = -f (x)\\
    \frac{1 - \alpha}{1 + \alpha}\alpha^{|z|} &
    \textmd{ if } -f (x) < z < m - f (x)\\
    \frac{\alpha^{m - f (x)}}{1 + \alpha} & \textmd{ if } z = m-f (x)\\
    0 & \textmd{ if } z > m - f (x)
  \end{array}
\right.
\]
Note the range of the truncated $\alpha$-geometric mechanism is
$\{ 0, 1, \ldots, m \}$. The truncated $\alpha$-geometric mechanism is
again oblivious; it is also $(- {\Delta (f)} \ln \alpha, 0)$-differentially
private for any query $f$ with sensitivity $\Delta (f)$.
The truncated $\frac{1}{2}$-geometric mechanism over $\{ 0, 1, \ldots, 5 \}$ is
given in Figure~\ref{figure:geometric-mechanism-table}.

\begin{figure}[tbh]
  \centering
  \begin{subfigure}{.40\columnwidth}
    \[
    \begin{array}{|c|c|c|c|c|c|c|}
      \hline
      \textmd{input/output} & 0 & 1 & 2 & 3 & 4 & 5\\
      \hline
      0 & {2}/{3}  & {1}/{6} & {1}/{12} & {1}/{24}  & {1}/{48} & {1}/{48}\\
      \hline
      1 & {1}/{3}  & {1}/{3} & {1}/{6} & {1}/{12}  & {1}/{24} & {1}/{24}\\
      \hline
      2 & {1}/{6}  & {1}/{6} & {1}/{3} & {1}/{6}   & {1}/{12} & {1}/{12}\\
      \hline
      3 & {1}/{12} & {1}/{12} & {1}/{6} & {1}/{3}   & {1}/{6} & {1}/{6}\\
      \hline
      4 & {1}/{24} & {1}/{24} & {1}/{12} & {1}/{6}   & {1}/{3} & {1}/{3}\\
      \hline
      5 & {1}/{48} & {1}/{48} & {1}/{24} & {1}/{12} & {1}/{6} & {2}/{3}\\
      \hline
    \end{array}
    \]
    \caption{$\frac{1}{2}$-Geometric Mechanism}
    \label{figure:geometric-mechanism-table}
  \end{subfigure}
  \hspace{.08\columnwidth}
  \begin{subfigure}{.50\columnwidth}
    \centering
  \resizebox{.85\columnwidth}{!}{
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node
      distance=2cm,node/.style={circle,draw}]
      \node[node] (i0) at (0,  1) { $s_0$ };
      \node at (0, 1.5) { $\mathit{in}_0$ };
      \node at (0, 0) { $\vdots$ };
      \node at (.8, -.8) { $\vdots$ };
      \node[node] (i5) at (0, -1) { $s_5$ };
      \node at (0, -.5) { $\mathit{in}_5$ };

      \node[node] (o0) at (4,  2.5) { $t_0$ };
      \node at (4, 3) { $\mathit{out}_0$ };
      \node[node] (o1) at (4,  1.5) { $t_1$ };
      \node at (4, 2) { $\mathit{out}_1$ };
      \node[node] (o2) at (4,  0.5) { $t_2$ };
      \node at (4, 1) { $\mathit{out}_2$ };
      \node[node] (o3) at (4, -0.5) { $t_3$ };
      \node at (4, 0) { $\mathit{out}_3$ };
      \node[node] (o4) at (4, -1.5) { $t_4$ };
      \node at (4, -1) { $\mathit{out}_4$ };
      \node[node] (o5) at (4, -2.5) { $t_5$ };
      \node at (4, -2) { $\mathit{out}_5$ };

      \path
      (i0) edge node [right=30,above=10] { $2/3$ } (o0)
      (i0) edge node [right=30,above=3] { $1/6$ } (o1)
      (i0) edge node [right=30,above=-3] { $1/12$ } (o2)
      (i0) edge node [right=30,below=-5] { $1/24$ } (o3)
      (i0) edge node [right=30,below] { $1/48$ } (o4)
      (i0) edge node [right=30,below=8] { $1/48$ } (o5)

      \hide{
      (i1) edge node [above] {  } (o0)
      (i1) edge node [above] {  } (o2)
      (i1) edge node [above] {  } (o3)
      (i1) edge node [above] {  } (o4)
      (i1) edge node [above] {  } (o5)

      (i2) edge node [above] {  } (o0)
      (i2) edge node [above] {  } (o2)
      (i2) edge node [above] {  } (o3)
      (i2) edge node [above] {  } (o4)
      (i2) edge node [above] {  } (o5)

      (i3) edge node [above] {  } (o0)
      (i3) edge node [above] {  } (o2)
      (i3) edge node [above] {  } (o3)
      (i3) edge node [above] {  } (o4)
      (i3) edge node [above] {  } (o5)

      (i4) edge node [above] {  } (o0)
      (i4) edge node [above] {  } (o2)
      (i4) edge node [above] {  } (o3)
      (i4) edge node [above] {  } (o4)
      (i4) edge node [above] {  } (o5)
      }

      (i5) edge node [right=10,above=16] { $1/48$ } (o0)
      \hide{
      (i5) edge node [above] {  } (o2)
      (i5) edge node [above] {  } (o3)
      (i5) edge node [above] {  } (o4)
      }
      (i5) edge node [right=15,below=8] { $2/3$ } (o5)
      ;
      \end{tikzpicture}
    }
    \caption{Markov Chain}
    \label{figure:geometric-mechanism-markov-chain}
  \end{subfigure}
  \caption{A Markov Chain for $\frac{1}{2}$-Geometric Mechanism}
  \label{figure:geometric-mechanism}\vspace*{-.5cm}
\end{figure}

Similar to the survey mechanism, it is straightforward to model the
truncated $\frac{1}{2}$-geometric mechanism as a Markov chain. 
Recall that the truncated $\frac{1}{2}$-geometric mechanism is
oblivious. It suffices to consider $\{ f (x) : x \in \mathcal{X}^n \}$
instead of $\mathcal{X}^n$ as inputs. 
Let the state $s_k$ and $t_l$
denote the input value $k$ and output value $l$ respectively. Define
the state set $S = \{ s_k, t_k : k \in \{ 0, 1, \ldots, m \} \}$.
The probability transition $\wp (s_k, t_l)$ is the probability of the
output value $l$ on the input value $k$ as defined in the
mechanism. Moreover, we have $\mathit{in}_k \in L (s_k)$ and
$\mathit{out}_k \in L (t_k)$ for $k \in \{ 0, 1, \ldots, n \}$.
If $\Delta (f) = 1$, $| f (x) - f (x') | \leq 1$ for every neighbors
$x, x' \in \mathcal{X}^n$. Subsequently, $s_k$ and $s_l$ are
neighbors iff $| k - l | \leq 1$ in our model.
Figure~\ref{figure:geometric-mechanism-markov-chain} gives
the Markov chain for the truncated
$\frac{1}{2}$-geometric mechanism over $\{ 0, 1, \ldots, 5 \}$.

\subsection{Subsampling}
\label{subsection:subsampling}

\input{subsampling}

